# Upload Flow - Sequential File Processing

## Overview

The multi-remote upload system processes files **sequentially** with **parallel remote uploads per file**.

## Upload Strategy

### âœ… Current Implementation

**Sequential File Processing:**
- Process ONE file at a time
- For each file, upload to ALL active remotes in parallel
- Wait for ALL remotes to complete (success or failure) before moving to next file

### Example Flow

**Scenario:** 5 files, 3 active remotes

```
Step 1: Process File 1 (vacation_1.jpg)
â”œâ”€ Thread 1: Upload to ğŸŸ¦ My S3         [IN_PROGRESS]
â”œâ”€ Thread 2: Upload to ğŸŸ© Google Drive  [IN_PROGRESS]
â””â”€ Thread 3: Upload to ğŸŸ§ Backup S3     [IN_PROGRESS]
     â”‚
     â””â”€ WAIT for ALL 3 to complete
          â”‚
          â”œâ”€ ğŸŸ¦ My S3        âœ“ Success (2.3s)
          â”œâ”€ ğŸŸ© Google Drive âœ“ Success (3.1s)
          â””â”€ ğŸŸ§ Backup S3    âŒ Failed (1.2s - Auth error)

Step 2: Process File 2 (vacation_2.jpg)
â”œâ”€ Thread 1: Upload to ğŸŸ¦ My S3         [IN_PROGRESS]
â”œâ”€ Thread 2: Upload to ğŸŸ© Google Drive  [IN_PROGRESS]
â””â”€ Thread 3: Upload to ğŸŸ§ Backup S3     [IN_PROGRESS]
     â”‚
     â””â”€ WAIT for ALL 3 to complete
          â”‚
          â”œâ”€ ğŸŸ¦ My S3        âœ“ Success (2.1s)
          â”œâ”€ ğŸŸ© Google Drive âœ“ Success (2.8s)
          â””â”€ ğŸŸ§ Backup S3    âœ“ Success (2.5s)

Step 3: Process File 3 (vacation_3.jpg)
... and so on
```

## Thread Model

### Concurrency

**Per File:**
- 3 remotes = 3 parallel threads
- 5 remotes = 5 parallel threads
- 10 remotes = 10 parallel threads

**Across Files:**
- Files are processed sequentially (one at a time)
- No limit on number of parallel remote uploads per file
- Each file waits for all its remote uploads to complete

### Thread Safety

**Mutex Protection:**
```kotlin
stateMutex.withLock {
    _uploadStates.update { ... }
}
```

**Async/Await Pattern:**
```kotlin
// Launch parallel uploads for one file
val uploadJobs = activeRemotes.map { remote ->
    scope.async(Dispatchers.IO) {
        uploadToRemote(file, remote)
    }
}

// Wait for ALL to complete
uploadJobs.awaitAll()

// Then move to next file
```

## Code Implementation

### Upload Coordinator

```kotlin
suspend fun uploadFiles(files: List<MediaFile>, scope: CoroutineScope) {
    val activeRemotes = remoteConfigRepository.getActiveRemotes()

    // Process files ONE AT A TIME
    files.forEach { file ->
        initializeFileState(file, activeRemotes)

        // Upload this file to ALL remotes in parallel
        val uploadJobs = activeRemotes.map { remote ->
            scope.async(Dispatchers.IO) {
                uploadToRemote(file, remote)
            }
        }

        // WAIT for ALL remotes to complete
        uploadJobs.awaitAll()

        // Only then move to next file
    }
}
```

## Benefits of This Approach

### âœ… Advantages

1. **Predictable Resource Usage**
   - Max concurrent uploads = number of active remotes (not unlimited)
   - Example: 3 remotes = max 3 threads at any time

2. **Thread Safety**
   - One file at a time prevents race conditions
   - Simpler state management

3. **Network Efficiency**
   - All remotes upload the same file simultaneously
   - File is read from disk once, sent to all remotes
   - No need to re-read file for each remote

4. **Progress Clarity**
   - User sees clear progress: "File 2 of 5 uploading..."
   - Easy to understand what's happening

5. **Memory Efficient**
   - Only one file's data in memory at a time
   - Even with 10 remotes, same file data is shared

### âš ï¸ Trade-offs

1. **Slower for Large Batches**
   - 100 files to 3 remotes: Each file waits for all 3 remotes
   - If one remote is slow, it blocks the next file

2. **Underutilized on Fast Networks**
   - If uploads are fast, there's downtime between files
   - Could theoretically upload more files simultaneously

## UI Experience

### Progress Display

**Sequential Processing Shows:**
```
Uploading Files
2 of 5 files completed

ğŸ“„ vacation_1.jpg (2.4 MB)
  ğŸŸ¦ My S3        âœ“ Uploaded
  ğŸŸ© Google Work  âœ“ Uploaded
  ğŸŸ§ Backup S3    âŒ Failed: Auth error

ğŸ“„ vacation_2.jpg (3.1 MB)  â† Currently uploading
  ğŸŸ¦ My S3        âœ“ Uploaded
  ğŸŸ© Google Work  â³ Uploading... 67%
  ğŸŸ§ Backup S3    â³ Uploading... 34%

ğŸ“„ vacation_3.jpg (1.8 MB)  â† Waiting
  ğŸŸ¦ My S3        ğŸ“‹ Queued
  ğŸŸ© Google Work  ğŸ“‹ Queued
  ğŸŸ§ Backup S3    ğŸ“‹ Queued
```

### User Perspective

1. User selects 5 files
2. Clicks Upload
3. Bottom sheet appears
4. File 1 uploads to all remotes in parallel
5. When File 1 is done (all remotes complete), File 2 starts
6. And so on...

## Performance Characteristics

### Time Calculation

**Sequential Processing:**
```
Total Time = Sum of (slowest remote per file)

Example:
File 1: max(2.3s, 3.1s, 1.2s) = 3.1s
File 2: max(2.1s, 2.8s, 2.5s) = 2.8s
File 3: max(1.9s, 2.2s, 2.0s) = 2.2s

Total: 3.1 + 2.8 + 2.2 = 8.1 seconds
```

### Resource Usage

**Memory:**
- One file's encrypted data in memory
- Streamed to all remotes simultaneously
- Peak: ~File Size (not File Size Ã— Remotes)

**Network:**
- Full bandwidth utilization per remote
- All remotes upload concurrently
- No artificial throttling

**Threads:**
- Active threads = Number of active remotes
- Max: Number of configured active remotes
- Min: 1 (if only 1 remote active)

## Error Handling

### Partial Failures

**Scenario:** File uploads successfully to 2/3 remotes

```
File 1:
â”œâ”€ ğŸŸ¦ My S3        âœ“ Success
â”œâ”€ ğŸŸ© Google Work  âœ“ Success
â””â”€ ğŸŸ§ Backup S3    âŒ Failed

Result: File 1 considered PARTIALLY successful
Action: Move to File 2
User Can: Retry failed remote individually later
```

### All Failures

**Scenario:** File fails on all remotes

```
File 1:
â”œâ”€ ğŸŸ¦ My S3        âŒ Network error
â”œâ”€ ğŸŸ© Google Work  âŒ Auth failed
â””â”€ ğŸŸ§ Backup S3    âŒ Bucket not found

Result: File 1 fully failed
Action: Still move to File 2 (don't block entire queue)
User Can: Fix configs and retry File 1 later
```

## Comparison with Alternative Approaches

### âŒ NOT Used: Full Parallel (All Files Ã— All Remotes)

```
Rejected approach:
- Upload ALL files to ALL remotes simultaneously
- Example: 5 files Ã— 3 remotes = 15 parallel operations
- Problem: Too many concurrent operations
- Risk: Memory pressure, network congestion
```

### âŒ NOT Used: Fully Sequential (One Remote at a Time)

```
Rejected approach:
- File 1 â†’ Remote 1, then Remote 2, then Remote 3
- Then File 2 â†’ Remote 1, then Remote 2, then Remote 3
- Problem: Very slow
- Time: 5 files Ã— 3 remotes Ã— 2s = 30 seconds total
```

### âœ… CHOSEN: Sequential Files, Parallel Remotes

```
Best of both worlds:
- File 1 â†’ All remotes in parallel (wait)
- File 2 â†’ All remotes in parallel (wait)
- Predictable resource usage
- Good performance
- Time: 5 files Ã— max(remote times) â‰ˆ 10-15 seconds
```

## Code Path

### 1. User Initiates Upload

```kotlin
// FolderViewModel.kt
fun uploadFiles(mediaFiles: List<MediaFile>) {
    viewModelScope.launch {
        multiRemoteUploadCoordinator.uploadFiles(mediaFiles, viewModelScope)
    }
}
```

### 2. Coordinator Processes Sequentially

```kotlin
// MultiRemoteUploadCoordinator.kt
suspend fun uploadFiles(files: List<MediaFile>, scope: CoroutineScope) {
    files.forEach { file ->  // SEQUENTIAL
        val uploadJobs = activeRemotes.map { remote ->
            scope.async { uploadToRemote(file, remote) }  // PARALLEL
        }
        uploadJobs.awaitAll()  // WAIT before next file
    }
}
```

### 3. UI Updates Reactively

```kotlin
// MultiRemoteUploadSheet.kt
val uploadStates by viewModel.uploadStates.collectAsState()

uploadStates.forEach { (fileId, state) ->
    FileUploadCard(state)  // Shows real-time progress
}
```

## Summary

**Upload Strategy:**
- âœ… Sequential file processing (one at a time)
- âœ… Parallel remote uploads (all remotes per file)
- âœ… Wait for all remotes before next file
- âœ… Thread-safe with Mutex
- âœ… Predictable resource usage
- âœ… Clean error handling

**Result:**
- Simple, predictable behavior
- Good performance for typical use cases
- Easy to understand and debug
- Safe resource management
